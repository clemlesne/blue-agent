{"/azure-pipelines-agent/about/":{"data":{"":"This project is open source and maintained by people like you. If you need help or found a bug, please feel free to open an issue on the clemlesne/azure-pipelines-agent GitHub project.\nThis project is not affiliated or endorsed by Microsoft.\nMicrosoft, Azure, Azure DevOps, Azure Pipelines, Windows Server, Debian, Ubuntu, Red Hat Enterprise Linux are trademarks of Microsoft Corporation, Canonical Ltd and Red Hat, Inc."},"title":"About"},"/azure-pipelines-agent/docs/":{"data":{"":"Azure Pipelines Agent is self-hosted agent in Kubernetes, cheap to run, secure, auto-scaled and easy to deploy.","features#Features":" üîÑ Agent register and restart itself. üèóÔ∏è Allow to build containers inside the agent using BuildKit. üîí Build authenticity can be cryptographically verified with Cosign and GPG. üìµ Can run air-gapped (no internet access). üí∞ Cheap to run (dynamic provisioning of agents, can scale from 0 to 100+ in few seconds with KEDA). üí™ Performances can be customized depending of the engineering needs, which goes far beyond the Microsoft-hosted agent. üñ•Ô∏è Pre-built with Windows Server, Debian, Ubuntu, Red Hat Enterprise Linux. üì¶ SBOM (Software Bill of Materials) is packaged with each container image. üîÑ System updates are applied every day. ","next#Next":" Getting startedQuick steps to deploy SecurityChain of trust \u0026 reporting a vulnerability "},"title":"Documentation"},"/azure-pipelines-agent/docs/advanced-topics/":{"data":{"":"Explore the following sections to learn how to use Azure Pipelines Agent:\nBuild ASP.NET applications Build Java applications Custom root certificate Capabilities Build container images Helm values Performance Provided software Proxy "},"title":"Advanced topics"},"/azure-pipelines-agent/docs/advanced-topics/build-aspnet/":{"data":{"":"It was chosen arbitrarily to install the LTS non SDK version of ASNP.NET. Because :\nLTS is better supported by Microsoft than STS The non-SDK is lighter when included in a container, knowing that not everyone will use it for building purposes It is recommended that development teams to hard-code the framework version you want to use, in your pipeline. With this setup, the developer controls its environment, not the platform. If they decide to upgrade, they update the pipeline, if not, not. This is under the responsibility of the developer.\nThe ASP.NET framework can be installed on the fly with UseDotNet@2:\n# azure-pipelines.yaml steps: - task: UseDotNet@2 inputs: packageType: sdk version: 7.0.5 Same way, if you want to use multiple versions of the framework, re-execute the task with the new version. Installations are cached locally."},"title":"Build ASP.NET applications"},"/azure-pipelines-agent/docs/advanced-topics/build-java/":{"data":{"":"Java (JDK and JVM) is not pre-installed into the agents. Specify the specific version you requires for your build. Install the framework with JavaToolInstaller@0, it configures both PATH and JAVA_HOME environements variables. The JDK file requires to be placed either in Azure Storage or in a local directory:\nAzure Storage (recommended for its audit, replication, and management by API capabilities), downlaod the binary from a central Azure Storage Local directory, in the context of a Kubernetes Pod, this directory could be a read-only shared volume mounted in the Pod First, create an Azure Storage account and a container named java-temurin. Then, upload the JDK file to the container. JDK can be downloaded, as example:\nfrom Eclipse Temurin from Microsoft Build of OpenJDK (recommended for its support), based on Eclipse Temurin, but with backported fixes and enhancements not yet been formally backported upstream Example of an example Azure Storage account named azure-pipelines-bins and a container java-temurin, with Eclipse Temurin JDK 17 and 21:\n# Azure Storage /java-temurin (container) /jdk /21 OpenJDK21U-jdk_aarch64_linux_hotspot_21.0.1_12.tar OpenJDK21U-jdk_x64_linux_hotspot_21.0.1_12.tar /17 OpenJDK17U-jdk_x64_linux_hotspot_17.0.9_9.tar [...] Example of the Azure Pipelines YAML file:\n# azure-pipelines.yaml steps: - task: JavaToolInstaller@0 inputs: azureCommonVirtualFile: jdk/21/OpenJDK21U-jdk_x64_linux_hotspot_21.0.1_12.tar azureContainerName: java-temurin azureResourceGroupName: AZURE_RESOURCE_GROUP_NAME azureResourceManagerEndpoint: AZURE_RESOURCE_MANAGER_SERVICE_CONNECTION_NAME azureStorageAccountName: azure-pipelines-bins jdkArchitectureOption: x64 jdkDestinationDirectory: $(agent.toolsDirectory)/jdk/21 jdkSourceOption: AzureStorage versionSpec: 21 "},"title":"Build Java applications"},"/azure-pipelines-agent/docs/advanced-topics/ca-certificate/":{"data":{"":"If you need to run the agent with a custom root certificate, you can use the following Helm values. Format is PEM certificate and with UTF-8 encoding.\nPaths are /app-root/azp-custom-certs for Linux-based agents and C:\\app-root\\azp-custom-certs for Windows-based agents.\n# config-root-ca.yaml apiVersion: v1 kind: ConfigMap metadata: name: custom-certs data: root-1.crt: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- root-2.crt: | -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- # values.yaml extraVolumes: - name: custom-certs configMap: name: custom-certs extraVolumeMounts: - name: custom-certs mountPath: /app-root/azp-custom-certs readOnly: true "},"title":"Custom root certificate"},"/azure-pipelines-agent/docs/advanced-topics/capabilities/":{"data":{"":"","#":"Capabilities are declarative variables you can add to the agents, to allow developers to select the right agent for their pipeline (official documentation).\n‚ÑπÔ∏è Multiple Helm instances can be deployed using the same agent pool name (see pipelines.poolName). It will result in a single pool with multiple capabilities. Be warning, if a capability is not unique accross the pool, all the agents will scale. This will create ‚Äúzoombies‚Äù agents, scaled for nothing, waiting their timeout. Disctinct the agents by capabilities. For examples:\nA pool of X64 agents, and a pool of ARM64 agents A pool of agents with GPU, and a pool of agents without GPU A pool of agents with low performance (standard usage), and a pool of agents with high performance (IA training, intensive C/Rust/GraalVM compilation, ‚Ä¶), with distinct Kubernetes Node pool, scaling to 0 when not used (AKS documentation) Example: ARM64 agents Take the assumption we want to host a specific instance pool to ARM servers.\n# values.yaml pipelines: poolName: private_kube capabilities: - arch_arm64 extraNodeSelectors: kubernetes.io/arch: arm64 Deploy the Helm instance:\n‚ùØ helm upgrade --install agent-arm64 clemlesne-azure-pipelines-agent/azure-pipelines-agent -f values.yaml Update the Azure Pipelines file in the repository to use the new pool:\n# azure-pipelines.yaml pool: name: private_kube demands: - arch_arm64 stages: ... Example: Use different agents on specific jobs In that example:\nWe are using a default agent on ARM64 Semgrep, our SAST tool, is not compatible with ARM64, let‚Äôs use X64 pool Our devs are working on a Java project, built with GraalVM, and the container is built locally with BuildKit: we need a system lot of RAM and multipe CPUs for building the application Our problematic:\nIs it possible to reconcile the efficiency of these different architectures, without restricting ourselves? Do we necessarily have to install high performance agents when the use of these large constructions is only a small part of the total execution time (tests, deployments, monitoring, rollback, external services, ‚Ä¶)? We decide to dpeloy these agents:\nDetails Efficiency (cost, perf, energy) Capabilities Standard performance, ARM64 ‚âÖ x1 arch_arm64, perf_standard Standard performance, X64 ‚âÖ x1.5 arch_x64, perf_standard High performance, ARM64 ‚âÖ x10 arch_x64, perf_high High performance, X64 ‚âÖ x15 arch_arm64, perf_high The developer can now use:\n# azure-pipelines.yaml pool: name: private_kube demands: - arch_arm64 - perf_standard stages: - stage: build jobs: - job: sast # Use X64 Linux agent because Semgrep is not available on ARM64 # See: https://github.com/returntocorp/semgrep/issues/2252 pool: name: private_kube demands: - arch_x64 - perf_standard - job: unit_tests - job: container # Use high performance agent as Java GraalVM compilation is complex pool: name: private_kube demands: - arch_x64 - perf_high - stage: deploy jobs: - job: upgrade - job: dast - job: integration_tests "},"title":"Capabilities"},"/azure-pipelines-agent/docs/advanced-topics/docker-in-docker/":{"data":{"":"","#":"These methods can be used to build a container image, at the time of writing:\nSoftware Ease Security Perf Run location Description Azure Container Registry task, Google Cloud Build üü©üü©üü• üü©üü©üü© üü©üü©üü© Managed environment A managed service build the container image in a dedicated environment. Kaniko üü©üü•üü• üü©üü©üü© üü©üü©üü• Self-hosted Kubernetes A Pod is created for each build, taking care of building and pushing the container to the registry. No security drawbacks. img, BuildKit üü©üü©üü© üü©üü©üü• üü©üü•üü• Local CLI CLI to build the images. Can build different architectures on a single machine. Requires Seccomp disabled and AppArmor disabled. Docker in docker üü©üü©üü© üü•üü•üü• üü©üü©üü© Local CLI Before Kubernetes 1.20, it was possible to build container images in the agent, using the Docker socket. This is not possible anymore, as Kubernetes deprecated the Docker socket in favor of the Container Runtime Interface. We choose BuildKit for this project. Its license allows commercial use, and the project and mainly maintained, as the time of writing, by Docker, Netlix and Microsoft.\nLinux systems are supported, but not Windows:\nRef Container build inside of the agent with BuildKit ghcr.io/clemlesne/azure-pipelines-agent:bookworm-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:bullseye-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:focal-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:jammy-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:ubi8-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:ubi9-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:win-ltsc2019-main ‚ùå ghcr.io/clemlesne/azure-pipelines-agent:win-ltsc2022-main ‚ùå How to use the bundled BuildKit There are two components, the backend, buildkitd, and the CLI, buildctl.\nRequirements:\nSetup special security requirements, you can find them in the example file container-build.yaml. In the pipeline, run buildkitd before using buildctl. # azure-pipelines.yaml variables: - name: container_name value: my-app - name: container_registry_domain value: my-app-registry.azurecr.io steps: - bash: | # Start buildkitd rootlesskit buildkitd --oci-worker-no-process-sandbox --addr $BUILDKIT_HOST \u0026 # Wait for buildkitd to start while ! buildctl debug workers; do sleep 1; done displayName: Run BuildKit - bash: | buildctl build \\ --frontend dockerfile.v0 \\ --local context=. \\ --local dockerfile=. \\ --output type=image,name=$(container_registry_domain)/$(container_name):latest,push=true displayName: Build and push the image Out of the box, argument --opt platform=linux/amd64,linux/arm64 can be added to build an image compatible with multiple architectures (more can be specified). Multiple cache strategies are available (including container registry, Azure Storage Blob, AWS S3).\nBuildKit and the performance BuildKit works by virtualization in the user space. You can‚Äôt expect build times as short as native (on your laptop for example). QEMU is used as a backend. This has the advantage of being able to create images for different architectures than your processor. Virtualization-wise, not all CPU models are equivalent, you can refer to the official project documentation to select the most appropriated CPU model for your Kubernetes Node Pool."},"title":"Build container images"},"/azure-pipelines-agent/docs/advanced-topics/helm-values/":{"data":{"":" Parameter Description Default affinity Node affinity for pod assignment {} annotations Add custom annotations to the Pod. {} autoscaling.cooldown Time in seconds the automation will wait until there is no more pipeline asking for an agent. Same time is then applied for system termination. 60 autoscaling.enabled Enable the auto-scaling. Requires KEDA, but can be started without. Be warning, disabling auto-scaling implies a shutdown of the existing agents during a Helm instance upgrade, according to pipelines.timeout. true autoscaling.maxReplicas Maximum number of pods, remaining jobs will be kept in queue. The default value is arbitrary, to avoid misconfiguration. 100 extraEnv Additional environment variables for the agent container. [] extraManifests Extra manifests to deploy as an array. pod. [] extraNodeSelectors Additional node labels for pod assignment. {} extraVolumeMounts Additional volume mounts for the agent container. [] extraVolumes Additional volumes for the agent pod. [] fullnameOverride Overrides release fullname \"\" image.flavor Container image tag, can be bookworm, bullseye, focal, jammy, ubi8, ubi9, win-ltsc2019, or win-ltsc2022. bookworm image.isWindows Turn on is the agent is a Windows-based system. false image.pullPolicy Container image pull policy IfNotPresent image.repository Container image repository ghcr.io/clemlesne/azure-pipelines-agent:bullseye image.version Container image tag Version imagePullSecrets Use secrets to pull the container image. [] initContainers Init containers for the agent pod. pod. [] nameOverride Overrides release name \"\" pipelines.cache.size Total cache to attach to the Azure Pipelines standard directory. By default, same amount as the Microsoft Hosted agents. 10Gi pipelines.cache.type Disk type to attach to the Azure Pipelines standard directory. See your cloud provider for types (Azure, AWS). managed-csi (Azure compatible) pipelines.cache.volumeEnabled Enabled by default, can be disabled if your CSI driver doesn‚Äôt support ephemeral storage (exhaustive list). If disabled, it is advised to allow \u003e= 10Gi of ephemeral storage usage (see resources). true pipelines.capabilities Add demands/capabilities to the agent [] pipelines.cleanup.failed Maximum of failed Jobs to keep from Kubernetes API server (see doc). Only applied to autoscaled deployments (see autoscaling.enabled). 100 pipelines.cleanup.successful Maximum of successful Jobs to keep from Kubernetes API server (see doc). Only applied to autoscaled deployments (see autoscaling.enabled). 100 pipelines.cleanup.ttl Delay until Job history will be cleaned from Kubernetes API server (see doc). Only applied to autoscaled deployments (see autoscaling.enabled). 3600 (1 hour) pipelines.organizationURL The Azure base URL for your organization None pipelines.personalAccessToken Personal Access Token (PAT) used by the agent to connect to the Azure DevOps server (both SaaS and self-hosted). None pipelines.poolName Agent pool name to which the agent should register. None pipelines.timeout Time in seconds after a agent will be stopped, the same amount of time is applied as a timeout for the system to shut down. 3600 (1 hour) pipelines.tmpdir.size Total size of the standard TMPDIR directory. 1Gi pipelines.tmpdir.type Disk type to attach to the standard TMPDIR directory. See your cloud provider for types (Azure, AWS). managed-csi (Azure compatible) pipelines.tmpdir.volumeEnabled Enabled by default, can be disabled if your CSI driver doesn‚Äôt support ephemeral storage (exhaustive list). If disabled, it is advised to allow \u003e= 10Gi of ephemeral storage usage (see resources). true podSecurityContext Security rules applied to the Pod (more details). {} replicaCount Default fixed amount of agents deployed. Those are not auto-scaled. 3 resources Resource limits { \"resources\": { \"limits\": { \"cpu\": 2, \"memory\": \"4Gi\", \"ephemeral-storage\": \"8Gi\" }, \"requests\": { \"cpu\": 1, \"memory\": \"2Gi\", \"ephemeral-storage\": \"2Gi\" }}} secret.create Create Secret, must contains personalAccessToken and organizationURL variables. true secret.name Secret name Release name securityContext Security rules applied to the container (more details). {} serviceAccount.annotations Custom annotations to give to the ServiceAccount. {} serviceAccount.create Create ServiceAccount true serviceAccount.name ServiceAccount name Release name sidecarContainers Containers to run alongside the agent container. [] tolerations Toleration labels for pod assignment. [] "},"title":"Helm values"},"/azure-pipelines-agent/docs/advanced-topics/performance/":{"data":{"":"These actions can enhance your system performance:\nEnough CPU and memory are allocated to the agent (see resources). See the your Kubernetes monitoring software to detect bottlenecks (notably CPU, RAM, IOPS, network, disk size). No emptyDir is used (see pipelines.cache.volumeEnabled, pipelines.tmpdir.volumeEnabled, and extraVolumes). SSD volumes are used for both cache (see pipelines.cache) and system temporary directory (see pipelines.tmpdir). For exemple, in Azure, the managed-csi-premium volume type is a high-performance SSD. The network bewteen Azure DevOps server and agents has a low latency. BuikdKit specifics:\nChoose an ephemeral disk for the cache in /app-root/.local/share/buildkit, instead of an emptyDir. Use an high-performance disk for the cache, exemple managed-csi-premium in Azure. "},"title":"Performance"},"/azure-pipelines-agent/docs/advanced-topics/provided-software/":{"data":{"":"","#":"Softwares are operating system specific. The following table lists the softwares provided by the agent.\nLinux Azure Pipelines agent + requirements BuildKit + requirements (dbus-user-session, fuse-overlayfs, iptables, shadow-utils, uidmap) Cloud providers CLIs AWS CLI Azure CLI Google Cloud SDK Shells bash (default) PowerShell Core zsh Programming languages ASP.NET Core Runtime Python (Python 3.8, Python 3.9, Python 3.10, Python 3.11, depending of the system, plus C/Rust build tools for libs non pre-built on the platforms) Tools git gzip jq make tar unzip wget yq zip zstd Windows Azure Pipelines agent + requirements Cloud providers CLIs AWS CLI Azure CLI Google Cloud SDK Shells PowerShell Core (default) Windows PowerShell Programming languages .NET SDK Python 3.11 Visual Studio Build Tools (with AzureBuildTools, VCTools, WebBuildTools, ManagedDesktopBuildTools, OfficeBuildTools workloads) Tools git jq yq zstd "},"title":"Provided software"},"/azure-pipelines-agent/docs/advanced-topics/proxy/":{"data":{"":"If you need to use a proxy, you can set the following environment variables. See this documentation for more details.\n# values.yaml extraEnv: - name: VSTS_HTTP_PROXY value: http://proxy:8080 - name: VSTS_HTTP_PROXY_USERNAME value: username - name: VSTS_HTTP_PROXY_PASSWORD value: password "},"title":"Proxy"},"/azure-pipelines-agent/docs/getting-started/":{"data":{"":"","docker-hub-images#Docker Hub images":"Container images are both published to GitHub Container Registry and Docker Hub. URLs showed in the doc are GitHub Container Registry URLs, for simplicity. To use Docker Hub, replace ghcr.io/clemlesne/azure-pipelines-agent by docker.io/clemlesne/azure-pipelines-agent. Docker Hub images are signed and secured the same way. See the images at hub.docker.com.","os-support-matrix#OS support matrix":" Ref OS Size Arch Support ghcr.io/clemlesne/azure-pipelines-agent:bookworm-main Debian Bookworm (12) slim amd64, arm64/v8 See Debian LTS wiki. ghcr.io/clemlesne/azure-pipelines-agent:bullseye-main Debian Bullseye (11) slim amd64, arm64/v8 See Debian LTS wiki. ghcr.io/clemlesne/azure-pipelines-agent:focal-main Ubuntu Focal (20.04) minimal amd64, arm64/v8 See Ubuntu LTS wiki. ghcr.io/clemlesne/azure-pipelines-agent:jammy-main Ubuntu Jammy (22.04) minimal amd64, arm64/v8 See Ubuntu LTS wiki. ghcr.io/clemlesne/azure-pipelines-agent:ubi8-main Red Hat UBI 8 minimal amd64, arm64/v8 See Red Hat product life cycles. ghcr.io/clemlesne/azure-pipelines-agent:ubi9-main Red Hat UBI 9 minimal amd64, arm64/v8 See Red Hat product life cycles. ghcr.io/clemlesne/azure-pipelines-agent:win-ltsc2019-main Windows Server 2019 Core amd64 See base image servicing lifecycles. ghcr.io/clemlesne/azure-pipelines-agent:win-ltsc2022-main Windows Server 2022 Core amd64 See base image servicing lifecycles. ","usage#Usage":" Prepare the Azure DevOps organization Create a new agent pool in Azure DevOps. Then, create the personal access token allowing access from the Agent to Azure DevOps.\nPrepare the Helm values Minimal configuration:\n# values.yaml pipelines: organizationURL: https://dev.azure.com/your-organization personalAccessToken: your-pat poolName: your-pool Details about the Helm configuration can be found in a dedicated section.\nInstall the chart Use Helm to install the latest released chart:\nhelm repo add clemlesne-azure-pipelines-agent https://clemlesne.github.io/azure-pipelines-agent helm repo update helm upgrade --install agent clemlesne-azure-pipelines-agent/azure-pipelines-agent "},"title":"Getting started"},"/azure-pipelines-agent/docs/security/":{"data":{"":"","chain-of-trust#Chain of trust":"Both the containers and the Helm chart are signed:\nContainers Containers are signed with Cosign.\nCosign public key is available in /cosign.pub.\n# Example of verification with Cosign ‚ùØ cosign verify --key cosign.pub ghcr.io/clemlesne/azure-pipelines-agent:bullseye-main Verification for ghcr.io/clemlesne/azure-pipelines-agent:bullseye-main -- The following checks were performed on each of these signatures: - The cosign claims were validated - Existence of the claims in the transparency log was verified offline - The signatures were verified against the specified public key Helm chart Helm chart is signed with two methods, Cosign and GPG. Both methods can be used to confirm authenticity of a build.\nKeys:\nCosign public key is available in /cosign.pub. GPG public key is available on Keybase and in /pubring.gpg. # Example of verification with Helm native signature ‚ùØ helm fetch --keyring pubring.gpg --verify clemlesne-azure-pipelines-agent/azure-pipelines-agent --version 5.0.0 Signed by: Cl√©mence Lesn√© \u003cclemence@lesne.pro\u003e Using Key With Fingerprint: 417E701DBC66834CA752C920460D072B9C032DFD Chart Hash Verified: sha256:1c23e22cffc132ce12489480d139b59e97b3cb49ff1599a4ae11fb5c317c1e64 # Example of verification with Cosign ‚ùØ VERSION=5.0.0 ‚ùØ wget https://github.com/clemlesne/azure-pipelines-agent/releases/download/azure-pipelines-agent-${VERSION}/azure-pipelines-agent-${VERSION}.tgz.bundle ‚ùØ helm pull clemlesne-azure-pipelines-agent/azure-pipelines-agent --version 5.0.0 ‚ùØ cosign verify-blob azure-pipelines-agent-${VERSION}.tgz --bundle azure-pipelines-agent-${VERSION}.tgz.bundle --key cosign.pub Verified OK ","proactive-detection-of-vulnerabilities#Proactive detection of vulnerabilities":"At each build, a vulnerability scan is performed on the system. If a vulnerability that can be upgraded is detected, the build is stopped and the image is not pushed to the registry. Vulnerability is reported in GitHub Security. The maintainers are alterted and have access to reports.\nAutomation is supported by Snyk and Semgrep. Helm chart, configuration files, and containers, are scanned for vulnerabilities and misconfigurations.\nScanned systems:\nRef Vulnerability scans with Snyk ghcr.io/clemlesne/azure-pipelines-agent:bookworm-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:bullseye-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:focal-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:jammy-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:ubi8-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:ubi9-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:win-ltsc2019-main ‚úÖ ghcr.io/clemlesne/azure-pipelines-agent:win-ltsc2022-main ‚úÖ ","reliability-notes#Reliability notes":"Systems are built every days. Each image is accompanied by a SBOM (Software Bill of Materials) which allows to verify that the installed packages are those expected. This speed has the advantage of minimizing exposure to security flaws, which will then be corrected on the build environments in 24 hours.\nNevertheless it can happen that a package provider (e.g. Debian, Canonical, Red Hat) deploys a system update that introduces a bug. This is difficult to predict.\nEach image is pushed with a unique tag, which corresponds to the date of the last update (example: bullseye-20230313 for a build on March 13, 2023). It is therefore possible to fix the download of a version by modifying the image.version property to 20230313.","reporting-a-vulnerability#Reporting a vulnerability":"If you think you have found a vulnerability, please do not open an issue on GitHub. Instead, please send an email to Cl√©mence Lesn√©."},"title":"Security"},"/azure-pipelines-agent/docs/troubleshooting/":{"data":{"":"","change-buildkit-working-directory#Change Buildkit working directory":"If need Buildkit to write in another folder, then create the buildkitd.toml file and set the root variable. Example below (bash in the pipeline):\nmkdir ~/.config/buildkit echo 'root = \"/app-root/.local/tmp/buildkit\"' \u003e ~/.config/buildkit/buildkitd.toml ","container-fails-to-a-containerstatusunknown-state#Container fails to a \u003ccode\u003eContainerStatusUnknown\u003c/code\u003e state":"Pods are evicted by Kubernetes with the message Pod ephemeral local storage usage exceeds the total limit of containers This error is due to the fact that the default ephemeral storage limit is set to a lower value than the one used by the pipeline. You can fix it by setting the value to more than default value in resources.limits.ephemeral-storage.\nThis error notably happens when using BuildKit with an emptyDir and a large number of layers.\n# values.yaml (extract) resources: limits: ephemeral-storage: 16Gi Pods are started but never selected by Azure DevOps when using multiple architectures Prefer hardcoding the architecture in both the pipeline and the Helm values. As this, KEDA will be able to select the right pods matching the architecture. Otherwise, there is a possibility that the deployment selected by KEDA is not matching the requested architecture.\n# azure-pipelines.yaml (extract) stages: - stage: test jobs: - job: test pool: demands: - arch_x64 # values.yaml (extract) extraNodeSelectors: kubernetes.io/arch: arm64 pipelines: capabilities: - arch_arm64 Container fails to a ContainerStatusUnknown state Error is often due to two things:\nKubernetes is not able to pull the image: check the image name and the credentials, if you are using the public registry, mind the domain whitelist Pod has been ecivted by Kubernetes due to the excessive local storage usage: parameter ephemeral-storage in resources Helm values is set to 8Gi by default, you can increase it to 16Gi for example ","namespaces-must-be-set-to-a-non-zero-value#Namespaces must be set to a non-zero value":"This error is due to the fact that BuildKit needs to create a new user namespace, and the default maximum number of namespaces is 0. Value is defined by user.max_user_namespaces (documentation). You can fix it by setting the value to more than 1000. Issue notably happens on AWS Bottlerocket OS. See related issue.\nWe can update dynamically the host system settings with a DaemonSet:\n# daemonset.yaml apiVersion: apps/v1 kind: DaemonSet metadata: labels: app.kubernetes.io/component: sysctl app.kubernetes.io/name: sysctl-max-user-ns-fix app.kubernetes.io/part-of: azure-pipelines-agent name: sysctl-max-user-ns-fix spec: selector: matchLabels: app.kubernetes.io/name: sysctl-max-user-ns-fix template: metadata: labels: app.kubernetes.io/name: sysctl-max-user-ns-fix spec: containers: - name: sysctl-max-user-ns-fix image: docker.io/library/busybox:1.36 command: [ \"sh\", \"-euxc\", \"sysctl -w user.max_user_namespaces=63359 \u0026\u0026 sleep infinity\", ] securityContext: privileged: true ","pods-are-evicted-by-kubernetes-with-the-message-pod-ephemeral-local-storage-usage-exceeds-the-total-limit-of-containers#Pods are evicted by Kubernetes with the message \u003ccode\u003ePod ephemeral local storage usage exceeds the total limit of containers\u003c/code\u003e":"","pods-are-started-but-never-selected-by-azure-devops-when-using-multiple-architectures#Pods are started but never selected by Azure DevOps when using multiple architectures":"","the-agent-has-exceeded-the-60-minute-time-limit#The agent has exceeded the 60-minute time limit":"If the pipeline takes longer than 60 minutes, you need to change two things.\nThe technical pipeline timeout with pipelines.timeout Helm value to 7200 seconds (2 hours) for example. Increase the functional pipeline timeout in Azure DevOps. Go to Options \u003e Build job \u003e Build job timeout in minutes. ‚ÑπÔ∏è Set a technical pipeline timeout longer than the functional pipeline timeout to avoid the system to kill the pipeline abruptly. "},"title":"Troubleshooting"}}